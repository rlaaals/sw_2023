{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b681e-370a-4cfa-a452-dd2d7f0cd77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Union\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('using GPU ', torch.cuda.current_device())\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using CPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff3de5-0d0e-497b-ac75-d5179a3f65d3",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e1d83-8670-407b-82f6-bf9652f58639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 디코딩 함수\n",
    "def rle_decode(mask_rle: Union[str, int], shape=(224, 224)) -> np.array:\n",
    "    '''\n",
    "    mask_rle: run-length as string formatted (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    if mask_rle == -1:\n",
    "        return np.zeros(shape)\n",
    "    \n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def dice_score(prediction: np.array, ground_truth: np.array, smooth=1e-7) -> float:\n",
    "    '''\n",
    "    Calculate Dice Score between two binary masks.\n",
    "    '''\n",
    "    intersection = np.sum(prediction * ground_truth)\n",
    "    return (2.0 * intersection + smooth) / (np.sum(prediction) + np.sum(ground_truth) + smooth)\n",
    "\n",
    "\n",
    "def calculate_dice_scores(ground_truth_df, prediction_df, img_shape=(224, 224)) -> List[float]:\n",
    "    '''\n",
    "    Calculate Dice scores for a dataset.\n",
    "    '''\n",
    "    \n",
    "    # Keep only the rows in the prediction dataframe that have matching img_ids in the ground truth dataframe\n",
    "    prediction_df = prediction_df[prediction_df.iloc[:, 0].isin(ground_truth_df.iloc[:, 0])]\n",
    "    prediction_df.index = range(prediction_df.shape[0])\n",
    "\n",
    "    # Extract the mask_rle columns\n",
    "    pred_mask_rle = prediction_df.iloc[:, 1]\n",
    "    gt_mask_rle = ground_truth_df.iloc[:, 1]\n",
    "\n",
    "\n",
    "    def calculate_dice(pred_rle, gt_rle):\n",
    "        pred_mask = rle_decode(pred_rle, img_shape)\n",
    "        gt_mask = rle_decode(gt_rle, img_shape)\n",
    "\n",
    "        if np.sum(gt_mask) > 0 or np.sum(pred_mask) > 0:\n",
    "            return dice_score(pred_mask, gt_mask)\n",
    "        else:\n",
    "            return None  # No valid masks found, return None\n",
    "\n",
    "    dice_scores = Parallel(n_jobs=-1)(\n",
    "        delayed(calculate_dice)(pred_rle, gt_rle) for pred_rle, gt_rle in zip(pred_mask_rle, gt_mask_rle)\n",
    "    )\n",
    "\n",
    "    dice_scores = [score for score in dice_scores if score is not None]  # Exclude None values\n",
    "\n",
    "\n",
    "    return np.mean(dice_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be76a29e-e9c2-411a-a569-04166f074184",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8496767-2f64-4285-bec4-c6f53a1fd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                    A.Resize(224, 224),\n",
    "                    A.Normalize(),\n",
    "                    ToTensorV2(transpose_mask=True)\n",
    "                ])\n",
    "\n",
    "train_mask_transform = A.Compose([\n",
    "                    A.Resize(224, 224),\n",
    "                    ToTensorV2(transpose_mask=True)\n",
    "                ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                    A.Resize(224, 224),\n",
    "                    A.Normalize(),\n",
    "                    ToTensorV2(transpose_mask=True)\n",
    "                ])\n",
    "\n",
    "class SatelliteDatasetTraining(Dataset):\n",
    "    def __init__(self, input_path='./input224', transform=train_transform, mask_transform=train_mask_transform):\n",
    "        mask_path = input_path.replace('input', 'mask')\n",
    "        self.input_data = [input_path + '/' + input_filename for input_filename in os.listdir(input_path)]\n",
    "        self.mask_data = [mask_path + '/' + mask_filename for mask_filename in os.listdir(mask_path)]\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.input_data[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mask = cv2.imread(self.mask_data[idx], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        augmented_image = self.transform(image = image)\n",
    "        augmented_mask = self.mask_transform(image = mask)\n",
    "        image = augmented_image['image']\n",
    "        mask = augmented_mask['image']\n",
    "        \n",
    "        mask[mask != 0] = 1\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "class SatelliteDatasetInfer(Dataset):\n",
    "    def __init__(self, csv_file, transform = None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        image = self.transform(image=image)['image']\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc955893-22fd-4320-88be-7aa0d790cbd9",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b708503-2ff9-4584-9d73-40990b3572f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SatelliteDatasetTraining(transform=train_transform, mask_transform=train_mask_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07bd973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_to_check = dataset\n",
    "\n",
    "sample_indices = np.random.choice(len(dataset_to_check), size=2, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    index = sample_indices[i]\n",
    "    sample = dataset_to_check[index]\n",
    "\n",
    "    image = np.transpose(sample[0], (1, 2, 0))\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    index = sample_indices[i]\n",
    "    sample = dataset[index]\n",
    "\n",
    "    mask = sample[1].numpy()\n",
    "    mask = np.squeeze(mask)\n",
    "\n",
    "    ax.imshow(mask, cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42501fc-b573-4893-a7c4-5e280dfdaf09",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73228d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "resnet = torchvision.models.resnet.resnet50(pretrained=True)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Helper module that consists of a Conv -> BN -> ReLU\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.with_nonlinearity = with_nonlinearity\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if self.with_nonlinearity:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bridge(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the middle layer of the UNet which just consists of some\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.bridge = nn.Sequential(\n",
    "            ConvBlock(in_channels, out_channels),\n",
    "            ConvBlock(out_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bridge(x)\n",
    "\n",
    "\n",
    "class UpBlockForUNetWithResNet50(nn.Module):\n",
    "    \"\"\"\n",
    "    Up block that encapsulates one up-sampling step which consists of Upsample -> ConvBlock -> ConvBlock\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, up_conv_in_channels=None, up_conv_out_channels=None,\n",
    "                 upsampling_method=\"conv_transpose\"):\n",
    "        super().__init__()\n",
    "\n",
    "        if up_conv_in_channels == None:\n",
    "            up_conv_in_channels = in_channels\n",
    "        if up_conv_out_channels == None:\n",
    "            up_conv_out_channels = out_channels\n",
    "\n",
    "        if upsampling_method == \"conv_transpose\":\n",
    "            self.upsample = nn.ConvTranspose2d(up_conv_in_channels, up_conv_out_channels, kernel_size=2, stride=2)\n",
    "        elif upsampling_method == \"bilinear\":\n",
    "            self.upsample = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "            )\n",
    "        self.conv_block_1 = ConvBlock(in_channels, out_channels)\n",
    "        self.conv_block_2 = ConvBlock(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, up_x, down_x):\n",
    "        \"\"\"\n",
    "\n",
    "        :param up_x: this is the output from the previous up block\n",
    "        :param down_x: this is the output from the down block\n",
    "        :return: upsampled feature map\n",
    "        \"\"\"\n",
    "        x = self.upsample(up_x)\n",
    "        x = torch.cat([x, down_x], 1)\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNetWithResnet50Encoder(nn.Module):\n",
    "    DEPTH = 6\n",
    "\n",
    "    def __init__(self, n_classes=1):\n",
    "        super().__init__()\n",
    "        resnet = torchvision.models.resnet.resnet50(pretrained=True)\n",
    "        down_blocks = []\n",
    "        up_blocks = []\n",
    "        self.input_block = nn.Sequential(*list(resnet.children()))[:3]\n",
    "        self.input_pool = list(resnet.children())[3]\n",
    "        for bottleneck in list(resnet.children()):\n",
    "            if isinstance(bottleneck, nn.Sequential):\n",
    "                down_blocks.append(bottleneck)\n",
    "        self.down_blocks = nn.ModuleList(down_blocks)\n",
    "        self.bridge = Bridge(2048, 2048)\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(2048, 1024))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(1024, 512))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(512, 256))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=128 + 64, out_channels=128,\n",
    "                                                    up_conv_in_channels=256, up_conv_out_channels=128))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet50(in_channels=64 + 3, out_channels=64,\n",
    "                                                    up_conv_in_channels=128, up_conv_out_channels=64))\n",
    "\n",
    "        self.up_blocks = nn.ModuleList(up_blocks)\n",
    "\n",
    "        self.out = nn.Conv2d(64, n_classes, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x, with_output_feature_map=False):\n",
    "        pre_pools = dict()\n",
    "        pre_pools[f\"layer_0\"] = x\n",
    "        x = self.input_block(x)\n",
    "        pre_pools[f\"layer_1\"] = x\n",
    "        x = self.input_pool(x)\n",
    "\n",
    "        for i, block in enumerate(self.down_blocks, 2):\n",
    "            x = block(x)\n",
    "            if i == (UNetWithResnet50Encoder.DEPTH - 1):\n",
    "                continue\n",
    "            pre_pools[f\"layer_{i}\"] = x\n",
    "\n",
    "        x = self.bridge(x)\n",
    "\n",
    "        for i, block in enumerate(self.up_blocks, 1):\n",
    "            key = f\"layer_{UNetWithResnet50Encoder.DEPTH - 1 - i}\"\n",
    "            x = block(x, pre_pools[key])\n",
    "        output_feature_map = x\n",
    "        x = self.out(x)\n",
    "        del pre_pools\n",
    "        if with_output_feature_map:\n",
    "            return x, output_feature_map\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0895765-fba0-4fd9-b955-a6c0e43012e9",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34904559",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1e-7):\n",
    "\n",
    "        inputs = torch.sigmoid(inputs) # sigmoid를 통과한 출력이면 주석처리\n",
    "\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.0*intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "class DiceBCELoss(torch.nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1e-7):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2.0*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "        BCE = torch.nn.functional.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "\n",
    "        return Dice_BCE\n",
    "\n",
    "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
    "\n",
    "    def __init__(self, gamma=0, size_average=None, ignore_index=-100,\n",
    "                 reduce=None, balance_param=1.0):\n",
    "        super(FocalLoss, self).__init__(size_average)\n",
    "        self.gamma = gamma\n",
    "        self.size_average = size_average\n",
    "        self.ignore_index = ignore_index\n",
    "        self.balance_param = balance_param\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs and targets are assumed to be BatchxClasses\n",
    "\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        # compute the negative likelyhood\n",
    "        logpt = - torch.nn.functional.binary_cross_entropy_with_logits(inputs, targets)\n",
    "        pt = torch.exp(logpt)\n",
    "\n",
    "        # compute the loss\n",
    "        focal_loss = -((1 - pt) ** self.gamma) * logpt\n",
    "        balanced_focal_loss = self.balance_param * focal_loss\n",
    "        return balanced_focal_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63efb381-98c6-4d9b-a3b6-bd11c7fa8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use K-fold for cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "best_model_per_fold_list = [''] * k_folds\n",
    "best_model_score = [0] * k_folds\n",
    "dataset_list = list(range(len(dataset)))\n",
    "\n",
    "# 하이퍼파라미터\n",
    "epoch_num = 100\n",
    "learning_rate = 0.0001\n",
    "patience = 5\n",
    "\n",
    "best_dice_score = 0\n",
    "counter = 0\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(dataset_list)):\n",
    "    print(f\"Fold {fold + 1} / {k_folds}\")\n",
    "    \n",
    "    dataset = SatelliteDatasetTraining(transform=train_transform)\n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "    # model 초기화\n",
    "    model = UNetWithResnet50Encoder().to(device)\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "\n",
    "    # loss function과 optimizer 정의\n",
    "    criterion = DiceLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.002, steps_per_epoch=len(train_dataloader), epochs=epoch_num)\n",
    "    \n",
    "    # training loop\n",
    "    for epoch in range(epoch_num):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for images, masks in tqdm(train_dataloader):\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        epoch_loss /= len(train_dataloader)\n",
    "            \n",
    "        # validation\n",
    "        epoch_val_loss = 0\n",
    "        dice_scores_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images, masks in tqdm(val_dataloader):\n",
    "                images = images.float().to(device)\n",
    "                masks = masks.float().to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                val_loss = criterion(outputs, masks.unsqueeze(1))\n",
    "                epoch_val_loss += val_loss.item()\n",
    "                \n",
    "                masks = masks.cpu().numpy()\n",
    "\n",
    "                pred_masks = torch.sigmoid(outputs).cpu().numpy()\n",
    "                pred_masks = np.squeeze(pred_masks, axis=1)\n",
    "                pred_masks = (pred_masks > 0.35).astype(np.uint8) # Threshold = 0.35\n",
    "\n",
    "                pred_df = pd.DataFrame(columns=[\"img_id\", \"rle_mask\"])\n",
    "                gt_df = pd.DataFrame(columns=[\"img_id\", \"rle_mask\"])\n",
    "\n",
    "                for img_id, (pred_mask, mask) in enumerate(zip(pred_masks, masks)):\n",
    "                    pred_rle = rle_encode(pred_mask)\n",
    "                    gt_rle = rle_encode(mask)\n",
    "                    pred_df.loc[img_id] = [img_id, pred_rle]\n",
    "                    gt_df.loc[img_id] = [img_id, gt_rle]\n",
    "                    \n",
    "                dice_score_batch = calculate_dice_scores(gt_df, pred_df)\n",
    "                dice_scores_list.append(dice_score_batch)\n",
    "\n",
    "        avg_dice_score = np.mean(dice_scores_list)\n",
    "        epoch_val_loss /= len(val_dataloader)\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {epoch_loss}, Val Loss: {epoch_val_loss}, Val Dice Score: {avg_dice_score}')\n",
    "        #print(f'Learning Rate for Epoch {epoch+1}: {optimizer.param_groups[0][\"lr\"]}')\n",
    "        #scheduler.step()\n",
    "        \n",
    "        if avg_dice_score > best_dice_score:\n",
    "            best_dice_score = avg_dice_score\n",
    "            counter = 0\n",
    "            best_model_name = f'best_model_fold{fold+1}_epoch{epoch+1}.pt'\n",
    "            torch.save(model.state_dict(), best_model_name)\n",
    "            best_model_per_fold_list[fold] = best_model_name\n",
    "            best_model_score[fold] = avg_dice_score\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print('Early Stopping')\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32eb51c-a3fe-4e11-a616-3a717ba16f7e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12371c8b-0c78-47df-89ec-2d8b55c8ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SatelliteDatasetInfer(csv_file='./test.csv', transform=test_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b431c-ac8e-4c40-9046-4d53e4bab14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetWithResnet50Encoder().to(device)\n",
    "model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "\n",
    "# load best model\n",
    "best_fold = best_model_score.index(max(best_model_score))\n",
    "model.load_state_dict(torch.load(best_model_per_fold_list[best_fold]))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    result = []\n",
    "    for images in tqdm(test_dataloader):\n",
    "        images = images.float().to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        masks = torch.sigmoid(outputs).cpu().numpy()\n",
    "        masks = np.squeeze(masks, axis=1)\n",
    "        masks = (masks > 0.35).astype(np.uint8) # Threshold = 0.35\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            mask_rle = rle_encode(masks[i])\n",
    "            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n",
    "                result.append(-1)\n",
    "            else:\n",
    "                result.append(mask_rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31890af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_indices = np.random.choice(len(test_dataset), size=2, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    index = sample_indices[i]\n",
    "    sample = test_dataset[index]\n",
    "\n",
    "    image = np.transpose(sample, (1, 2, 0))\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    index = sample_indices[i]\n",
    "    sample = rle_decode(result[index])\n",
    "\n",
    "    mask = np.squeeze(sample)\n",
    "\n",
    "    ax.imshow(mask, cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c2cbbb-04f1-4f9c-b4df-4b744dfce046",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6543d00-32b3-4f2d-a572-d0879fd0a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['mask_rle'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10cb6f-0826-4755-a376-97b695ae8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_name = 'resnet_unet_224data_submit.csv'\n",
    "submit.to_csv(submit_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381acbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.read_csv(submit_name)\n",
    "print('test size: ', len(submit_df['mask_rle']))\n",
    "cnt = 0\n",
    "for mask_rle in submit_df['mask_rle']:\n",
    "    if mask_rle == '-1':\n",
    "        cnt += 1\n",
    "print('pred -1: ', cnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.14 (NGC 22.12/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
